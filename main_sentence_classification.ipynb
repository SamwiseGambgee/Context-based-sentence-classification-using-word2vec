{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Based Sentence Classification\n",
    "\n",
    "### This program classifies sentences based on the context and predicts whether a sentence might be related to a \"patient\" or \"doctor\" spoken sentences.\n",
    "\n",
    "\n",
    "<strong> Run the cell below to import all the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the required modules and the helper functions \n",
    "\n",
    "import numpy as np \n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# the following two modules are helper functions to generate features from the sentences\n",
    "def get_feature(text,feature_dimension,wordset,model, label = None):\n",
    "    features = None\n",
    "\n",
    "    for sample in text:\n",
    "        paragraph = sample.lower()\n",
    "        sentences = sent_tokenize(paragraph)\n",
    "\n",
    "        for sentence in sentences:\n",
    "            feature_vector = np.zeros(feature_dimension)\n",
    "            words = word_tokenize(sentence)\n",
    "\n",
    "            count = 0\n",
    "            for word in words:\n",
    "                if word in wordset and word.isalnum():\n",
    "                    count = count + 1\n",
    "                    feature_vector = feature_vector + model[word]\n",
    "\n",
    "            if count != 0:\n",
    "                feature_vector = feature_vector / float(count)\n",
    "\n",
    "                if label is not None:\n",
    "                    feature_vector = np.append(feature_vector, label)\n",
    "\n",
    "                feature_vector = feature_vector[np.newaxis]\n",
    "\n",
    "                if features is None:\n",
    "                    features = feature_vector\n",
    "                else:\n",
    "                    features = np.concatenate((features, feature_vector))\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def generate_features(feature_dimension,wordset,model):\n",
    "\n",
    "    with open(\"patient.txt\") as patfile:\n",
    "        patient = patfile.readlines()\n",
    "    patfile.close()\n",
    "\n",
    "    with open(\"doctor.txt\") as docfile:\n",
    "        doctor = docfile.readlines()\n",
    "    docfile.close()\n",
    "\n",
    "    patient_features = get_feature(patient,feature_dimension,wordset,model,label=0)\n",
    "    doctor_features = get_feature(doctor,feature_dimension,wordset,model,label=1)\n",
    "\n",
    "    features = np.concatenate((patient_features,doctor_features))\n",
    "    return features\n",
    "\n",
    "def predict(text,feature_dimension, wordset, model):\n",
    "    paragraph = text.lower()\n",
    "    sentences = sent_tokenize(paragraph)   \n",
    "    \n",
    "    pred = clf.predict(get_feature([text],feature_dimension,wordset,model))\n",
    "                       \n",
    "    for i,item in enumerate(pred):\n",
    "        if item == 0:\n",
    "            ret = \"patient\"\n",
    "        else:\n",
    "            ret = \"doctor\"\n",
    "\n",
    "        print(\"{} : {}\".format(sentences[i],ret))\n",
    "    \n",
    "    print()\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection \n",
    "\n",
    "The data is crawled from www.askthedoctor.com.\n",
    "The website contains data of questions asked by the patients, and the corresponding answers given by the doctor.\n",
    "The data is categorized into different categories based on the diseases. Here, each of the category is looped and corresponding data is stored as \"patient\" data or \"doctor\" data\n",
    "Run the code below to collect data from the above website. \n",
    "Two files \"patient.txt\" and \"doctor.txt\" are saved\n",
    "\n",
    "<strong>Note that it might take several minutes depending on the internet connection. \n",
    "\n",
    "<strong>Skip the below cell if the data is already saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data ... \n",
      "Abortion\n",
      "Acid Reflux\n",
      "ACL Injuries\n",
      "Acne\n",
      "Acute Renal Failure\n",
      "ADD and ADHD\n",
      "Addiction and Substance Abuse\n",
      "Adolescent Nutrition\n",
      "Adoption\n",
      "Age-Related Macular Degeneration\n",
      "Aging\n",
      "AIDS\n",
      "Alcohol Abuse\n",
      "Allergies\n",
      "Alternative Exercises\n",
      "Alzheimer\n",
      "Anal Fissure\n",
      "Anemia\n",
      "Angina\n",
      "Anorexia Nervosa\n",
      "Antioxidants\n",
      "Anxiety and Panic\n",
      "Appendicitis\n",
      "Arrhythmia\n",
      "Arthritis\n",
      "Asthma\n",
      "Athlete Training\n",
      "Athlete\n",
      "Atrial Fibrillation\n",
      "Autism\n",
      "Avian Flu\n",
      "Baby Milestones\n",
      "Baby Sleep\n",
      "Baby Teething\n",
      "Back Pain\n",
      "Bad Breath\n",
      "Beauty and Skin\n",
      "Bed Bugs\n",
      "Better Sex\n",
      "Binge Eating Disorder\n",
      "Bipolar Disorder\n",
      "Bird Flu\n",
      "Birth Control\n",
      "Bladder Cancer\n",
      "Bladder Infections\n",
      "Blisters\n",
      "Bloating\n",
      "Bloody Urine\n",
      "Bloody Urine\n",
      "BMI\n",
      "Body Building\n",
      "Body Piercings\n",
      "Bone Spurs\n",
      "Botox\n",
      "Brain and Nervous System\n",
      "Brain Cancer\n",
      "Breast Cancer\n",
      "Breastfeeding\n",
      "Breathing Problems\n",
      "Bronchitis\n",
      "Bruises\n",
      "Budget Fitness\n",
      "Bulimia Nervosa\n",
      "Burns\n",
      "Bursitis\n",
      "Caffeine\n",
      "Calories\n",
      "Cancer\n",
      "Canker Sores\n",
      "Carbohydrates\n",
      "Cardio Fitness\n",
      "Carpal Tunnel Syndrome\n",
      "Cataracts\n",
      "Celiac Disease\n",
      "Cervical Cancer\n",
      "Cesarean Section\n",
      "Chest Pain\n",
      "Chicken Pox\n",
      "Child Development\n",
      "Child Discipline\n",
      "Children\n",
      "Chlamydia\n",
      "Cholesterol\n",
      "Cholesterol Management\n",
      "Chronic Fatigue Syndrome\n",
      "Chronic Kidney Disease\n",
      "Chronic Pelvic Pain\n",
      "Cloning\n",
      "Cold and Flu\n",
      "Cold Sores\n",
      "Colic\n",
      "Colorectal Cancer\n",
      "Conception\n",
      "Concussions\n",
      "Congestive Heart Failure\n",
      "Conjunctivitis\n",
      "Constipation\n",
      "Contraception\n",
      "Contraceptives\n",
      "COPD\n",
      "Coughs\n",
      "Crohn\n",
      "Croup\n",
      "Cysts\n",
      "Dandruff\n",
      "Dehydration\n",
      "Dental Care\n",
      "Depression\n",
      "Dermal Fillers\n",
      "Diabetes\n",
      "Diapering\n",
      "Diarrhea\n",
      "Diet & Fitness\n",
      "Diet and Nutrition\n",
      "Diet Pills\n",
      "Digestive Disorders\n",
      "Diverticulitis\n",
      "Dizziness\n",
      "Drug Interactions\n",
      "Drug Overdose\n",
      "Drugs\n",
      "Dry Skin\n",
      "Ear Infections\n",
      "Eating Disorders\n",
      "Eczema\n",
      "Edema\n",
      "Endometriosis\n",
      "Enlarged Prostate\n",
      "Epilepsey\n",
      "Epilepsy\n",
      "Erectile  Dysfunction\n",
      "Erection Problems\n",
      "Exercise\n",
      "Eye Health\n",
      "Fatigue\n",
      "Female Incontinence\n",
      "Fibroids\n",
      "Fibromyalgia\n",
      "First Time Sex\n",
      "Food Poisoning\n",
      "Formula Feeding\n",
      "Gallstones\n",
      "Gas\n",
      "Gastritis\n",
      "Gastroenteritis\n",
      "General\n",
      "Genes\n",
      "Genital Herpes\n",
      "Genital Warts and HPV\n",
      "GERD\n",
      "Gestational Diabetes\n",
      "Glycemic Index\n",
      "Gout\n",
      "Graves Disease\n",
      "Gynecomastia\n",
      "Hair Loss\n",
      "Head Lice\n",
      "Headaches\n",
      "Healthy Aging\n",
      "Healthy Eating\n",
      "Hearing Loss\n",
      "Heart Disease\n",
      "Heart Failure\n",
      "Heart Health\n",
      "Heartburn and GERD\n",
      "Heat Exhaustion\n",
      "Heat Rash\n",
      "Heatstroke\n",
      "Hematoma\n",
      "Hemorrhoids\n",
      "Hepatitis\n",
      "Hernia\n",
      "Herpes\n",
      "Hiccups\n",
      "High Blood Pressure\n",
      "High-Protein Diet\n",
      "HIV and AIDS\n",
      "Hives\n",
      "Hodgkin\n",
      "Hormonal Implants\n",
      "Hormone Replacement Therapy\n",
      "Hot Flashes\n",
      "Hyperhidrosis\n",
      "Hypertension\n",
      "Hyperthyroidism\n",
      "Hypothyroidism\n",
      "Immunizations\n",
      "Incontinence\n",
      "Infections\n",
      "Infertility\n",
      "Inflammatory Bowel Disease\n",
      "Error ................ Inflammatory Bowel Disease\n",
      "Ingrown Hair\n",
      "Ingrown Toenail\n",
      "Insect Bites\n",
      "Insomnia\n",
      "Insulin Resistance \n",
      "Integrative Medicine\n",
      "Irritable Bowel Syndrome\n",
      "Jaundice\n",
      "Jetlag\n",
      "Jock Itch\n",
      "Joint Damage\n",
      "Juvenile Diabetes\n",
      "Kidney Failure\n",
      "Kidney Infection\n",
      "Kidney Stones\n",
      "Knee Pain\n",
      "Knee Replacement Surgery\n",
      "Labor and Delivery\n",
      "Lactose Intolerance\n",
      "Laryngitis\n",
      "LDL Cholesterol\n",
      "Leukemia\n",
      "Lice\n",
      "Lipoma\n",
      "Liver Cancer\n",
      "Liver Failure\n",
      "Low Libido\n",
      "Low Testosterone\n",
      "Lower Back Pain\n",
      "Lumps\n",
      "Lumps\n",
      "Lung Cancer\n",
      "Lung Disease\n",
      "Error ................ Lung Disease\n",
      "Lupus\n",
      "Lyme Disease\n",
      "Macular Degeneration\n",
      "Mad Cow Disease\n",
      "Masturbation\n",
      "Error ................ Masturbation\n",
      "Masturbation\n",
      "Error ................ Masturbation\n",
      "Medicare\n",
      "Melanoma and Skin Cancer\n",
      "Memory Loss\n",
      "Men\n",
      "Meningitis\n",
      "Menopause\n",
      "Menstrual Cycle\n",
      "Menstruation\n",
      "Mental Health\n",
      "Metabolic Syndrome\n",
      "Metabolic Syndrome Que\n",
      "Migraines\n",
      "Migraines and Headaches\n",
      "Missed Period\n",
      "Mobile\n",
      "Moles\n",
      "Mono\n",
      "Morning Sickness\n",
      "Multiple Sclerosis\n",
      "Mumps\n",
      "Muscle Pain\n",
      "Nail Fungus\n",
      "Nail Problems\n",
      "Nausea\n",
      "Neurology\n",
      "Neurology\n",
      "Neuropathy\n",
      "Night Eating\n",
      "Non-Hodgkin\n",
      "NSAIDs\n",
      "nsulin Resistance\n",
      "Obesity\n",
      "Oral Health\n",
      "Organ Transplants\n",
      "Osteoarthritis\n",
      "Osteoporosis\n",
      "Ovarian Cancer\n",
      "Ovarian Cyst\n",
      "Overactive Bladder\n",
      "Ovulation Calendar\n",
      "Pain\n",
      "Pain Management\n",
      "Pancreatic Cancer\n",
      "Panic and Anxiety Disorders\n",
      "Pap Smears\n",
      "Parenting & Pregnancy\n",
      "Parkinson\n",
      "PCOS\n",
      "Pelvic Inflammatory Disease\n",
      "Pelvic Pain\n",
      "Perimenopause\n",
      "Peyronie\n",
      "Piercings\n",
      "Pink Eye\n",
      "Plantar Fasciitis\n",
      "Plantar Warts\n",
      "Plastic Surgery\n",
      "Pleurisy\n",
      "PMS\n",
      "Pneumonia\n",
      "Podiatry\n",
      "Poison Ivy\n",
      "Polyps, Colon\n",
      "Postpartum Depression\n",
      "Potty Training\n",
      "Pregnancy\n",
      "Pregnancy and Sex\n",
      "Pregnancy Loss\n",
      "Pregnancy Tests\n",
      "Premature Babies\n",
      "Premature Ejaculation\n",
      "Prenatal Testing\n",
      "Prostate Cancer\n",
      "Prostatitis\n",
      "Protection\n",
      "Protein\n",
      "Psoriasis\n",
      "Psoriatic Arthritis\n",
      "Quadriplegia\n",
      "Quit Smoking\n",
      "Quitting Smoking\n",
      "Rabies\n",
      "Rash\n",
      "Recipes\n",
      "Restless Legs Syndrome\n",
      "Rheumatoid Arthritis\n",
      "Ringworm\n",
      "Rosacea\n",
      "Rotator Cuff Injuries\n",
      "Running\n",
      "Safe Sex\n",
      "Scars\n",
      "Schizophrenia\n",
      "Sclerosis\n",
      "Seasonal Affective Disorder\n",
      "Seasonal Allergies\n",
      "Sex\n",
      "sex & beauty\n",
      "Sex & Beauty\n",
      "Sex and Relationships\n",
      "Sexual Conditions\n",
      "Sexual Health\n",
      "Shin Splints\n",
      "Shingles\n",
      "Shoulder Pain\n",
      "Sinus Infection\n",
      "Skin Cancer\n",
      "Skin Rash\n",
      "Skin Tags\n",
      "Sleep Apnea\n",
      "Sleep Disorders\n",
      "Sleep Problems\n",
      "Smoking Cessation\n",
      "Snoring\n",
      "Sore Throat\n",
      "Spinal Fracture\n",
      "Spinal Injections\n",
      "Sports Injuries\n",
      "Staph Infection\n",
      "STD\n",
      "Stiff Neck\n",
      "Stomach Flu\n",
      "Stomach Pain\n",
      "Strength Training\n",
      "Strep Throat\n",
      "Stress Management\n",
      "Stretch Marks\n",
      "Stretching\n",
      "Stroke\n",
      "Stye\n",
      "Sunburn\n",
      "Sunscreen\n",
      "Supplements\n",
      "Swine Flu\n",
      "Swollen Lymph Nodes\n",
      "Syphilis\n",
      "Tendinitis\n",
      "Tennis Elbow\n",
      "Testicular Cancer\n",
      "Throat Cancer\n",
      "Thyroid Disorders\n",
      "Thyroid Nodules\n",
      "TIA - Transient Ischemic Attack\n",
      "Tick Bites\n",
      "Toddler Behavior\n",
      "Toddler Milestones\n",
      "Tonsillitis\n",
      "Topics A-Z\n",
      "Torn Ligaments\n",
      "Trans Fats\n",
      "Transplants\n",
      "Travel Fitness\n",
      "Tremors and Shaking\n",
      "Triglycerides\n",
      "Trimesters\n",
      "Tumors\n",
      "Ulcerative Colitis\n",
      "Ulcers\n",
      "Uncategorized\n",
      "Urinary Tract Infection\n",
      "Uterine and Cervical Cancer\n",
      "Uterine Fibroids\n",
      "Vaginal Discharge\n",
      "Vaginal Dryness\n",
      "Vaginal Health\n",
      "Vaginitis\n",
      "Varicose Veins\n",
      "Error ................ Varicose Veins\n",
      "Vertigo\n",
      "Viral Gastroenteritis\n",
      "Viral Meningitis\n",
      "Vitamins\n",
      "Warts\n",
      "Weight Gain\n",
      "Weight Lifting\n",
      "Weight Loss\n",
      "West Nile Virus\n",
      "White Blood Cells\n",
      "Wisdom Teeth\n",
      "Women\n",
      "Wound\n",
      "Wrinkles\n",
      "X-Rays\n",
      "Yeast Infection\n",
      "Yeast Infections\n",
      "Yoga\n",
      "Yoga and Meditation\n",
      "Zone Diet\n",
      "Zoster (Herpes) Virus\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_url = \"https://www.askthedoctor.com/browse-medical-questions\"\n",
    "base_f = urllib.request.urlopen(base_url)\n",
    "base_soup = BeautifulSoup(base_f,\"lxml\")\n",
    "\n",
    "# categories of diseases \n",
    "categories = [(base_anchor[\"href\"],base_anchor[\"title\"]) for base_div in base_soup.findAll(\"div\",{\"class\":\"disease_column\"}) for base_anchor in base_div.findAll(\"a\",{\"itemtype\":\"https://schema.org/category\"})]\n",
    "\n",
    "\n",
    "print(\"Collecting data ... \")\n",
    "\n",
    "with open(\"patient.txt\",\"w\") as patientfile, open(\"doctor.txt\", \"w\") as doctorfile:\n",
    "    for category in categories:\n",
    "\n",
    "        topic = category[1]\n",
    "        print(topic)\n",
    "\n",
    "        try:\n",
    "            url = category[0]\n",
    "            f = urllib.request.urlopen(url)\n",
    "            soup = BeautifulSoup(f,\"lxml\")\n",
    "\n",
    "            divs = soup.findAll('div',{\"class\":\"question_az\"})\n",
    "\n",
    "            for i,div in enumerate(divs):\n",
    "                inner_url = div.find('a')['href']\n",
    "                inner_f = urllib.request.urlopen(inner_url)\n",
    "                inner_soup = BeautifulSoup(inner_f,\"lxml\")\n",
    "\n",
    "                question = inner_soup.find('span',{\"class\":\"quesans\"})\n",
    "                question = question.text.replace(\",\",\" \")\n",
    "                question = re.sub('[.]+', '.',question)\n",
    "\n",
    "\n",
    "                for token in sent_tokenize(question):\n",
    "                    if len(word_tokenize(token)) > 3:\n",
    "                        patientfile.write(\"{}\\n\".format(token))\n",
    "\n",
    "                answer = inner_soup.find('span', {\"class\": \"answer quesans\"})\n",
    "                answer = answer.text.replace(\"\"\" \\n(adsbygoogle = window.adsbygoogle || []).push({});\"\"\",\"\").replace(\"\\n\",\" \").replace(\"   \",\" \").replace(\",\",\" \")\n",
    "                answer = re.sub('[.]+', '.',answer)\n",
    "\n",
    "                for token in sent_tokenize(answer):\n",
    "                    if len(word_tokenize(token)) > 3:\n",
    "                        doctorfile.write(\"{}\\n\".format(token))\n",
    "\n",
    "        except:\n",
    "            print(\"Error ................ {}\".format(topic))\n",
    "            \n",
    "patientfile.close()\n",
    "doctorfile.close()\n",
    "\n",
    "print(\"Data saved !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "Word2vec is a method of word embeddings where the words in a sentence are mapped to their corresponding vectors representation.\n",
    "Here the whole dataset is considered, both patient and doctor spoken sentences to learn word embeddings.\n",
    "\n",
    "A python library \"gensim\" is used to train a word2vec model\n",
    "\n",
    "<strong> Run the code below to generate a word2vec model. \n",
    "<string> Skip the cell below if model is already created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwares\\Anacondas\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2017-09-07 06:23:34,642 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2017-09-07 06:23:34,708 : INFO : collecting all words and their counts\n",
      "2017-09-07 06:23:34,713 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-09-07 06:23:34,859 : INFO : PROGRESS: at sentence #10000, processed 149033 words, keeping 9961 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-07 06:23:35,020 : INFO : PROGRESS: at sentence #20000, processed 294765 words, keeping 13963 word types\n",
      "2017-09-07 06:23:35,103 : INFO : collected 15461 word types from a corpus of 375367 raw words and 25415 sentences\n",
      "2017-09-07 06:23:35,108 : INFO : Loading a fresh vocabulary\n",
      "2017-09-07 06:23:35,195 : INFO : min_count=5 retains 4644 unique words (30% of original 15461, drops 10817)\n",
      "2017-09-07 06:23:35,198 : INFO : min_count=5 leaves 357715 word corpus (95% of original 375367, drops 17652)\n",
      "2017-09-07 06:23:35,278 : INFO : deleting the raw counts dictionary of 15461 items\n",
      "2017-09-07 06:23:35,284 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2017-09-07 06:23:35,298 : INFO : downsampling leaves estimated 262582 word corpus (73.4% of prior 357715)\n",
      "2017-09-07 06:23:35,309 : INFO : estimated required memory for 4644 words and 300 dimensions: 13467600 bytes\n",
      "2017-09-07 06:23:35,392 : INFO : resetting layer weights\n",
      "2017-09-07 06:23:35,672 : INFO : training model with 4 workers on 4644 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2017-09-07 06:23:36,707 : INFO : PROGRESS: at 19.16% examples, 249737 words/s, in_qsize 7, out_qsize 0\n",
      "2017-09-07 06:23:37,709 : INFO : PROGRESS: at 44.23% examples, 288683 words/s, in_qsize 6, out_qsize 1\n",
      "2017-09-07 06:23:38,723 : INFO : PROGRESS: at 73.99% examples, 321566 words/s, in_qsize 6, out_qsize 0\n",
      "2017-09-07 06:23:39,407 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-09-07 06:23:39,413 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-09-07 06:23:39,424 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-09-07 06:23:39,441 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-09-07 06:23:39,443 : INFO : training on 1876835 raw words (1314112 effective words) took 3.7s, 350936 effective words/s\n",
      "2017-09-07 06:23:39,448 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-09-07 06:23:39,514 : INFO : saving Word2Vec object under word2vec_model, separately None\n",
      "2017-09-07 06:23:39,517 : INFO : not storing attribute syn0norm\n",
      "2017-09-07 06:23:39,519 : INFO : not storing attribute cum_table\n",
      "2017-09-07 06:23:39,726 : INFO : saved word2vec_model\n"
     ]
    }
   ],
   "source": [
    "data_matrix = [] \n",
    "\n",
    "with open(\"patient.txt\",\"r\") as patfile, open(\"doctor.txt\",\"r\") as docfile:\n",
    "    data_matrix = patfile.readlines()\n",
    "    data_matrix.extend(docfile.readlines())\n",
    "    \n",
    "patfile.close()\n",
    "docfile.close()\n",
    "\n",
    "# converting the whole data into lower case\n",
    "data_matrix = [sample.lower() for sample in data_matrix]\n",
    "\n",
    "print(\"The Dataset consists of {} sentences.\".format(len(data_matrix)))\n",
    "\n",
    "# Formatting the data to provide as input to gensim package's word2vec model\n",
    "words_matrix = []\n",
    "for sample in data_matrix:\n",
    "    sentences = sent_tokenize(sample)\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence)\n",
    "        words_new = [word for word in words if word.isalnum()]\n",
    "        words_matrix.append(words_new)\n",
    "        \n",
    "        \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Parameters required for training word2vec model\n",
    "num_features = 300    # Word vector dimensionality\n",
    "min_word_count = 5   # Minimum word count\n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size\n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(words_matrix, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling\n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and\n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"word2vec_model\"\n",
    "model.save(model_name)\n",
    "\n",
    "print(\"Word2Vec model saved !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Word2Vec Model \n",
    "\n",
    "Given a word, the model should be able to give similar words after being trained depending on the context words that appeared in sentences of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-07 06:36:25,961 : INFO : loading Word2Vec object from word2vec_model\n",
      "2017-09-07 06:36:26,384 : INFO : loading wv recursively from word2vec_model.wv.* with mmap=None\n",
      "2017-09-07 06:36:26,389 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-09-07 06:36:26,404 : INFO : setting ignored attribute cum_table to None\n",
      "2017-09-07 06:36:26,410 : INFO : loaded word2vec_model\n",
      "2017-09-07 06:36:26,484 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4644 words in the vocabulary and the dimension of the vectors is 300\n",
      "I\n",
      "[('you', 0.6624151468276978), ('answered', 0.6394109725952148), ('written', 0.6341018676757812), ('finds', 0.6296019554138184), ('appointments', 0.627862811088562), ('about', 0.6193121671676636), ('failed', 0.6178797483444214), ('anxious', 0.6176198720932007), ('helped', 0.6175113916397095), ('lastly', 0.6099379062652588)]\n",
      "\n",
      "swelling\n",
      "[('lymph', 0.9802428483963013), ('nodes', 0.9770952463150024), ('node', 0.9745349884033203), ('muscles', 0.9612188339233398), ('membrane', 0.9596492052078247), ('effect', 0.9512512683868408), ('skin', 0.950788676738739), ('vomiting', 0.9473362565040588), ('joint', 0.9470880627632141), ('element', 0.9426992535591125)]\n",
      "\n",
      "headache\n",
      "[('mild', 0.9848141670227051), ('pains', 0.9836372137069702), ('weakness', 0.9834761619567871), ('severe', 0.9823870062828064), ('chills', 0.9819514751434326), ('movement', 0.9815719127655029), ('sensation', 0.9811301231384277), ('fatigue', 0.9806628227233887), ('armpits', 0.9806625247001648), ('bowel', 0.9792762994766235)]\n",
      "\n",
      "fever\n",
      "[('less', 0.9697479009628296), ('mild', 0.9688019752502441), ('nausea', 0.9643539190292358), ('chronic', 0.9631041884422302), ('bowel', 0.9607267379760742), ('bleeding', 0.955062747001648), ('vomiting', 0.9544570446014404), ('itching', 0.9528419971466064), ('severe', 0.9528310298919678), ('fevers', 0.9517117142677307)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load(\"word2vec_model\")\n",
    "\n",
    "word_vectors = model.wv.syn0\n",
    "\n",
    "print(\"The model has {} words in the vocabulary and the dimension of the vectors is {}\".format(word_vectors.shape[0],word_vectors.shape[1]))\n",
    "\n",
    "\n",
    "print(\"I\\n{}\\n\".format(model.most_similar(\"i\")))\n",
    "print(\"swelling\\n{}\\n\".format(model.most_similar(\"swelling\")))\n",
    "print(\"headache\\n{}\\n\".format(model.most_similar(\"headache\")))\n",
    "print(\"fever\\n{}\\n\".format(model.most_similar(\"fever\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the features\n",
    "\n",
    "Each sentence vector is formed by averaging the vectors corresponding to each word in a sentence. \n",
    "\n",
    "The whole set of features is divided into train and test features.\n",
    "\n",
    "<strong> This might take some time\n",
    "<strong> Skip the cell if features are already saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> d:\\softwares\\anacondas\\anaconda3\\lib\\site-packages\\ipython\\core\\displayhook.py(236)__call__()\n",
      "-> def __call__(self, result=None):\n",
      "(Pdb) test_features.shape\n",
      "*** NameError: name 'test_features' is not defined\n",
      "(Pdb) features.shape\n",
      "*** NameError: name 'features' is not defined\n",
      "(Pdb) c\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load(\"word2vec_model\")\n",
    "word_vectors = model.wv.syn0\n",
    "\n",
    "feature_dimension = word_vectors.shape[1]\n",
    "\n",
    "# all words in the vocabulary\n",
    "wordset = set(model.wv.index2word)\n",
    "\n",
    "\n",
    "print(\"Generating features ...\")\n",
    "features = generate_features(feature_dimension,wordset,model)\n",
    "\n",
    "# dividing the dataset into train and test datasets.\n",
    "indices = np.random.permutation(features.shape[0])\n",
    "test_idx,training_idx = indices[:2000], indices[2000:]\n",
    "test_features, train_features = features[test_idx,:], features[training_idx,:]\n",
    "\n",
    "train_labels =  train_features[:,-1]\n",
    "train_features = train_features[:,:-1]\n",
    "\n",
    "test_labels =  test_features[:,-1]\n",
    "test_features = test_features[:,:-1]\n",
    "\n",
    "# Saving features \n",
    "np.save(\"train_features.npy\",train_features)\n",
    "np.save(\"train_labels.npy\", train_labels)\n",
    "np.save(\"test_features.npy\",test_features)\n",
    "np.save(\"test_labels.npy\",test_labels)\n",
    "\n",
    "print(\"Features saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Classifier Model\n",
    "\n",
    "A simple SVM classifier is trained by converting a sentence into vectors.\n",
    "\n",
    "<strong> Run the following code a train a simple SVM classifier and save the model. This might take some time\n",
    "<Strong> Skip the cell if model is already generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Model saved !\n"
     ]
    }
   ],
   "source": [
    "# Loading train features\n",
    "train_features = np.load(\"train_features.npy\")\n",
    "train_labels = np.load(\"train_labels.npy\")\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"linear\",C=100)\n",
    "\n",
    "print(\"Training classifier ....\")\n",
    "clf.fit(train_features,train_labels)\n",
    "\n",
    "import pickle \n",
    "\n",
    "with open(\"clf_model.pkl\",\"wb\") as clffile:\n",
    "    pickle.dump(clf,clffile)\n",
    "    \n",
    "clffile.close()\n",
    "\n",
    "print(\"Classifier Model saved !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for 2000 samples for the model : 85.45%\n"
     ]
    }
   ],
   "source": [
    "with open(\"clf_model.pkl\",\"rb\") as clffile:\n",
    "    clf = pickle.load(clffile)\n",
    "    \n",
    "clffile.close()\n",
    "   \n",
    "test_features = np.load(\"test_features.npy\")\n",
    "test_labels = np.load(\"test_labels.npy\")\n",
    "\n",
    "\n",
    "pred = clf.predict(test_features)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_labels,pred)*100\n",
    "\n",
    "print(\"The accuracy for {} samples for the model : {}%\".format(test_features.shape[0],acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out some random sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i still cough few times a day. : patient\n",
      "what should i do? : patient\n",
      "\n",
      "i have severe pain in my abdomen. : patient\n",
      "do i have to go to the doctor? : patient\n",
      "wash your hands everytime and follow hygenic practices : doctor\n",
      "\n",
      "wash your hands everytime and follow hygenic practices : doctor\n",
      "\n",
      "i have a sore throat. : patient\n",
      "it has been there for the past week. : patient\n",
      "\n",
      "do you have sore throat? : doctor\n",
      "does your throat feel itchy? : doctor\n",
      "do you have flu? : doctor\n",
      "\n",
      "you should apply neomycin ointment on your chin : doctor\n",
      "\n",
      "do you think it is an infection which might increase my blood pressure? : doctor\n",
      "yes, blood pressure will increase : doctor\n",
      "\n",
      "are you comfortable? : doctor\n",
      "if you are not comfortable, please let me know. : doctor\n",
      "no i am not comfortable and in too much in pain right now. : patient\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"clf_model.pkl\",\"rb\") as clffile:\n",
    "    clf = pickle.load(clffile)\n",
    "\n",
    "clffile.close()\n",
    "\n",
    "model = Word2Vec.load(\"word2vec_model\")\n",
    "word_vectors = model.wv.syn0\n",
    "\n",
    "feature_dimension = word_vectors.shape[1]\n",
    "\n",
    "# all words in the vocabulary\n",
    "wordset = set(model.wv.index2word)\n",
    "\n",
    "\n",
    "text = \"i still cough few times a day. what should i do?\"\n",
    "res = predict(text,feature_dimension, wordset, model)\n",
    "\n",
    "text = \"i have severe pain in my abdomen. do i have to go to the doctor? wash your hands everytime and follow hygenic practices\"\n",
    "res = predict(text,feature_dimension, wordset, model)\n",
    "\n",
    "text = \"wash your hands everytime and follow hygenic practices\"\n",
    "res = predict(text,feature_dimension, wordset, model)\n",
    "\n",
    "text = \"i have a sore throat. it has been there for the past week.\"\n",
    "res = predict(text,feature_dimension, wordset, model)\n",
    "\n",
    "text = \"do you have sore throat? Does your throat feel itchy? Do you have flu?\"\n",
    "res = predict(text,feature_dimension, wordset, model)\n",
    "\n",
    "\n",
    "text = \"you should apply neomycin ointment on your chin\"\n",
    "res = predict(text,feature_dimension, wordset, model)\n",
    "\n",
    "\n",
    "text = \"do you think it is an infection which might increase my blood pressure? Yes, blood pressure will increase\"\n",
    "res = predict(text,feature_dimension, wordset, model)\n",
    "\n",
    "text = \"Are you comfortable? If you are not comfortable, please let me know. No I am not comfortable and in too much in pain right now.\"\n",
    "res = predict(text,feature_dimension, wordset, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
